{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6F_u0cfZmK4",
        "outputId": "f50afe9e-6a86-45c5-cbbe-2a303f8cae79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.60)\n",
            "Collecting langchain_core\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.81.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.13.2)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.11.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_openai-0.3.18-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_core, langchain_openai, langchain_community\n",
            "  Attempting uninstall: langchain_core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.24 langchain_core-0.3.63 langchain_openai-0.3.18 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_openai langchain_community langchain_core -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qffzLUWZmK5"
      },
      "source": [
        "# function call 简介\n",
        "\n",
        "LLM的Function Call（函数调用）是一种功能，允许大型语言模型（如GPT）在生成文本的过程中调用外部函数或服务。通过这种方式，开发者可以定义各种函数，使得LLM能够根据对话的上下文和需求进行调用。这些函数可以用于数据提取、知识检索和API集成等任务，从而增强LLM的能力。\n",
        "具体来说，Function Call的作用包括：\n",
        "\n",
        "- 准确识别用户意图：将用户的语义转化为结构化的指令，从而准确判断需要调用哪个函数及其参数。\n",
        "- 增强对话能力：使得对话代理或聊天机器人能够处理复杂问题，通过调用外部API或知识库提供更相关和有用的响应。\n",
        "- 解决模型的局限性：通过引入工具插件来解决模型在时间处理和专业知识方面的缺陷，如幻觉问题。\n",
        "总结来说：function call能够让你用很少的提示词，让llm输出更加准确，数据结构更加稳定。\n",
        "\n",
        "我们还是用几个场景示例来说明，需要实现的功能如下："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW1huwuvZmK6"
      },
      "source": [
        "### 官网天气示例\n",
        "试想一下，如果我们询问北京天气，我们要从一段内容中提取参数location，并调用get_current_weather，获取结果，需要怎么做。在上一小节中，我们学习了json mode能力，可以写提示词，让ai帮我们提取包含location的对象，然后再传给函数得到结果，使用function calling该怎么实现呢。\n",
        "\n",
        "> 我们使用function_calling，把这个函数的描述告诉大模型，它就会返回给你这个函数所需要的参数。这个过程就会变得简洁、可控，结果更加准确。使用过程如下"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们来看openAI官网对于function calling给出的解释：**函数调用允许您向 Assistants API 描述函数**，并让它**智能地返回需要调用的函数及其参数**。\n",
        "\n",
        "它最大的特点可以总结为：能够让你用很少的提示词，让llm输出更加准确，数据结构更加稳定。"
      ],
      "metadata": {
        "id": "Epyg7UvudV72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZHEwcafZmK6",
        "outputId": "d85d6c75-d1dc-4686-c674-bdbea72bdb16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get_current_weather\n",
            "\n",
            "{'location': '北京'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "model = ChatOpenAI(model=\"qwen2.5-72b-instruct\").bind_tools(tools)\n",
        "res = model.invoke(\"北京的天气怎么样\")\n",
        "print(res.tool_calls[0][\"name\"])\n",
        "print()\n",
        "print(res.tool_calls[0][\"args\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "``` python\n",
        "\"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"location\": {\"type\": \"string\", \"description\": \"...\",},\n",
        "        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "    },\n",
        "    \"required\": [\"location\"],  # 必填参数\n",
        "}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "TuFsY-2QfiRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "生成函数调用请求\n",
        "当模型决定调用工具时，会按照指定的格式生成tool_calls列表，其中每个元素包含工具名称和参数。\n",
        "\n",
        "```\n",
        "res.tool_calls[0][\"name\"]：工具名称（此处为get_current_weather）。\n",
        "res.tool_calls[0][\"args\"]：工具所需的参数对象，包含解析出的location值。\n",
        "type(res.tool_calls[0][\"args\"]):参数的类型\n",
        "```"
      ],
      "metadata": {
        "id": "cM1FnIAGfUZL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP8XV2QXZmK7"
      },
      "source": [
        "### 数学运算示例\n",
        "\n",
        "上一个例子中，我们手写了json_schema来描述函数。但是，我们不能每次都自己手动做这件事，这样成本会变得很高。langchain提供了tool修饰符，可以增强工具，并允许大模型来绑定这些工具。在调用大模型时，自动帮我们生成json_schema。\n",
        "\n",
        "有一个计算函数，它接受两个整数参数 a 和 b，并返回它们的乘积。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9LwNIp3tZmK7"
      },
      "outputs": [],
      "source": [
        "def amultiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oa6b0iTZmK7",
        "outputId": "b62e5c08-2c58-4e68-cca4-2dcf069473e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 3, 'b': 6}\n",
            "<class 'dict'>\n",
            "18\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 定义一个工具函数，用于计算两个数的乘积 @tool\n",
        "@tool\n",
        "def amultiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "llm = ChatOpenAI(model=\"qwen2.5-72b-instruct\", temperature=0)\n",
        "\n",
        "# 将定义的工具函数绑定到模型上  bind_tools\n",
        "ll_tool = llm.bind_tools([amultiply])\n",
        "\n",
        "# 调用模型，传入参数并获取结果\n",
        "result = ll_tool.invoke('a 为 3 b 是 6')\n",
        "\n",
        "# 检查结果中是否包含工具调用，并打印相关信息\n",
        "if hasattr(result, 'tool_calls') and result.tool_calls:\n",
        "    print(result.tool_calls[0]['args'])  # 打印工具调用的参数\n",
        "    print(type(result.tool_calls[0]['args']))  # 打印参数的类型\n",
        "\n",
        "    # 调用 amultiply 工具函数，传入解析后的参数并打印结果\n",
        "    print(amultiply.invoke(result.tool_calls[0]['args']))\n",
        "else:\n",
        "    print(result.content)  # 如果没有工具调用，则打印内容"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(amultiply.invoke(result.tool_calls[0][\"args\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MORauxFfhfjM",
        "outputId": "92ddfe5c-25aa-405b-b000-c93930b29859"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content) ## 这里由于上下文完整，OpenAI将result.content置为空"
      ],
      "metadata": {
        "id": "DgmMmuZeifRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 需要注意的是，目前OpenAI在处理function_calling时表现更为**一致和可靠**。例如，当上下文中只包含信息a而缺少b时，OpenAI会通过result.content提醒用户需要补充b。而当上下文完整时，**OpenAI会返回result.tool_calls，并将result.content置为空**。\n",
        "- 相比之下，国内的一些模型（如Qwen和豆包）在处理function_calling时表现不够一致。例如，Qwen可能会伪造缺少的信息b，而豆包则可能在result.content和result.tool_calls中同时返回信息。因此，在使用这些模型时，开发者需要自行处理这些不一致的情况，以确保结果的准确性。"
      ],
      "metadata": {
        "id": "Ph1fQ38biQms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW7wSF7gZmK7"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.tools import tool\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_BASE\"] = userdata.get('OPENAI_API_BASE')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "idl1 = \"\"\"\n",
        "message ToolRequest {\n",
        "    string tool_id = 1;  // 工具的唯一标识符\n",
        "    int32 version = 2;   // 工具的版本号\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "idl2 = \"\"\"\n",
        "message ToolRequest {\n",
        "    string tool_name = 1;  // 工具的名称\n",
        "    int32 version = 2;     // 工具的版本号\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "idl3 = \"\"\"\n",
        "message ToolRequest {\n",
        "    string tool_category = 1;  // 工具的类别\n",
        "    int32 version = 2;         // 工具的版本号\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "idl4 = \"\"\"\n",
        "message ToolRequest {\n",
        "    string tool_description = 1;  // 工具的描述信息\n",
        "    int32 version = 2;            // 工具的版本号\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "class InterfaceDefinition(TypedDict):\n",
        "    path: str\n",
        "    description: str\n",
        "\n",
        "class PSMDefinition(TypedDict):\n",
        "    name: str\n",
        "    interfaces: List[InterfaceDefinition]\n",
        "\n",
        "\n",
        "interfaceMap: List[PSMDefinition] = [\n",
        "    {\n",
        "        \"name\": \"anchor.psm1\",\n",
        "        \"interfaces\": [\n",
        "            {\n",
        "                \"path\": \"/ark/anchor1\",\n",
        "                \"idl\": idl1\n",
        "            },\n",
        "            {\n",
        "                \"path\": \"/ark/anchor2\",\n",
        "                \"idl\": idl2\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"webcast.psm2\",\n",
        "        \"interfaces\": [\n",
        "            {\n",
        "                \"path\": \"/webcast/tool1\",\n",
        "                \"idl\": idl3\n",
        "            },\n",
        "            {\n",
        "                \"path\": \"/webcast/tool2\",\n",
        "                \"idl\": idl4\n",
        "            },\n",
        "        ],\n",
        "    },\n",
        "]\n",
        "\n",
        "def find_idl_by_name_and_path(psm, path):\n",
        "    for psmInfo in interfaceMap:\n",
        "        if psmInfo[\"name\"] == psm:\n",
        "            for interface in psmInfo[\"interfaces\"]:\n",
        "                if interface[\"path\"] == path:\n",
        "                    return interface[\"idl\"]\n",
        "\n",
        "class ConfigDict(BaseModel):\n",
        "    path: str = Field(description=\"包含 path 和 psm 的字典\")\n",
        "    psm: str = Field(description=\"接口对应的psm，示例：aaa.bbb.ccc，字母和.组成\")\n",
        "\n",
        "class ExplainKeyByPathInput(BaseModel):\n",
        "    queryInfo: ConfigDict = Field(description=\"包含 path 和 psm 的字典\")\n",
        "    keyName: str = Field(description=\"字段名称\")\n",
        "\n",
        "@tool(\"explain-key-by-path\", args_schema=ExplainKeyByPathInput)\n",
        "def explain_key_by_path(\n",
        "    queryInfo: ConfigDict,  # 定义一个包含 path 和 psm 的字典\n",
        "    keyName: Annotated[str, \"字段名称\"],\n",
        "):\n",
        "    \"\"\"字段解释工具，通过接口地址和接口对应的psm查找接口定义，并根据字段名来获取字段说明\"\"\"\n",
        "    # 你可以选择不使用 config 参数\n",
        "    print(queryInfo)\n",
        "    idl = find_idl_by_name_and_path(**queryInfo.dict())  # 将 ConfigDict 转换为字典\n",
        "\n",
        "    return idl\n",
        "\n",
        "print(explain_key_by_path.args_schema.schema())\n",
        "\n",
        "llm2 = ChatOpenAI(model=\"qwen2.5-72b-instruct\", temperature=0)\n",
        "\n",
        "llm_tool = llm2.bind_tools([explain_key_by_path])\n",
        "\n",
        "result = llm_tool.invoke('查询psm:webcast.psm2 接口 /webcast/tool2 中的 tool_name字段')\n",
        "\n",
        "if hasattr(result, 'tool_calls') and result.tool_calls:\n",
        "    print(result.tool_calls[0]['args'])\n",
        "    print(explain_key_by_path.invoke(result.tool_calls[0]['args']))\n",
        "else:\n",
        "    print(result.content)\n",
        "\n",
        "\n",
        "\n",
        "# # 示例使用\n",
        "# name = \"anchor.psm1\"\n",
        "# path = \"/ark/anchor2\"\n",
        "# idl = find_idl_by_name_and_path(name, path)\n",
        "# print(idl)  # 输出: idl1\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3110",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}